{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc7db756-79c2-4dd6-af9e-41e4df1e97fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def prepare_dataloaders(\n",
    "    path, batch_size=32, num_workers=2, val_split=0.2, test_split=0.1, augment=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepares train, validation, and test dataloaders from an ImageFolder dataset.\n",
    "    Supports optional data augmentation for the training set.\n",
    "\n",
    "    Args:\n",
    "        path (str): Root directory path to the dataset.\n",
    "        batch_size (int): Number of samples per batch.\n",
    "        num_workers (int): Number of subprocesses for data loading.\n",
    "        val_split (float): Fraction of data to use for validation.\n",
    "        test_split (float): Fraction of data to use for testing.\n",
    "        augment (bool): If True, apply augmentation to training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader or None)\n",
    "    \"\"\"\n",
    "    # Base transform (resize + normalize)\n",
    "    base_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Augmented transform for training only\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load full dataset (with base transform first)\n",
    "    full_dataset = datasets.ImageFolder(root=path, transform=base_transform)\n",
    "\n",
    "    total_size = len(full_dataset)\n",
    "    test_size = int(total_size * test_split)\n",
    "    val_size = int(total_size * val_split)\n",
    "    train_size = total_size - val_size - test_size\n",
    "\n",
    "    if test_split > 0:\n",
    "        train_set, val_set, test_set = random_split(\n",
    "            full_dataset,\n",
    "            [train_size, val_size, test_size],\n",
    "            generator=torch.Generator().manual_seed(42),\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=False,\n",
    "        )\n",
    "    else:\n",
    "        train_set, val_set = random_split(\n",
    "            full_dataset,\n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(42),\n",
    "        )\n",
    "        test_loader = None\n",
    "\n",
    "    # Apply augmentation only to training subset if requested\n",
    "    if augment:\n",
    "        train_set.dataset.transform = aug_transform\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Simple MTSD model\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "# ========== ECA and Backbone ==========\n",
    "class ECALayer(nn.Module):\n",
    "    def __init__(self, channels, k_size=3):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(\n",
    "            1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x).squeeze(-1).transpose(1, 2)\n",
    "        y = self.conv(y).transpose(1, 2).unsqueeze(-1)\n",
    "        y = self.sigmoid(y)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class Branch(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class MultiBranchNet(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            BottleneckBlock(input_channels, 64),\n",
    "            BottleneckBlock(64, 128),\n",
    "            BottleneckBlock(128, 256),\n",
    "            BottleneckBlock(256, 512),\n",
    "        ])\n",
    "        self.att = nn.ModuleList([\n",
    "            ECALayer(64),\n",
    "            ECALayer(128),\n",
    "            ECALayer(256),\n",
    "            ECALayer(512),\n",
    "        ])\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            Branch(64, num_classes),\n",
    "            Branch(128, num_classes),\n",
    "            Branch(256, num_classes),\n",
    "            Branch(512, num_classes),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features, logits = [], []\n",
    "        for i in range(4):\n",
    "            x = self.blocks[i](x)\n",
    "            x = self.att[i](x)\n",
    "            features.append(x)\n",
    "            logits.append(self.classifiers[i](x))\n",
    "        return logits, features\n",
    "\n",
    "\n",
    "def compute_asm(feature_map, target_size=None, max_hw=400):\n",
    "    if target_size is not None:\n",
    "        feature_map = F.interpolate(\n",
    "            feature_map, size=target_size, mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "    B, C, H, W = feature_map.size()\n",
    "    if max_hw < H * W:\n",
    "        feature_map = F.adaptive_avg_pool2d(\n",
    "            feature_map, (int(max_hw**0.5), int(max_hw**0.5))\n",
    "        )\n",
    "    F_T = feature_map.view(B, C, -1)\n",
    "    sim = torch.bmm(F_T.transpose(1, 2), F_T)\n",
    "    norm = torch.norm(sim, dim=(1, 2), keepdim=True) + 1e-6\n",
    "    return sim / norm\n",
    "\n",
    "\n",
    "def compute_total_loss(preds, feats, labels, alpha=3, beta=0.3, gamma=3000, delta=None):\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    l1 = ce(preds[3], labels)\n",
    "    l2 = sum(ce(preds[i], labels) for i in range(3))\n",
    "    kl_loss, asm_loss = 0, 0\n",
    "    target_size = feats[3].shape[2:]\n",
    "    for i in range(3):\n",
    "        pi = F.log_softmax(preds[i], dim=1)\n",
    "        for j in range(i + 1, 4):\n",
    "            pj = F.softmax(preds[j].detach(), dim=1)\n",
    "            kl = F.kl_div(pi, pj, reduction=\"batchmean\")\n",
    "            asm_s = compute_asm(feats[i], target_size)\n",
    "            asm_t = compute_asm(feats[j].detach(), target_size)\n",
    "            if asm_s.shape != asm_t.shape:\n",
    "                min_shape = list(map(min, asm_s.shape, asm_t.shape))\n",
    "                asm_s = asm_s[:, : min_shape[1], : min_shape[2]]\n",
    "                asm_t = asm_t[:, : min_shape[1], : min_shape[2]]\n",
    "            asm = F.mse_loss(asm_s, asm_t)\n",
    "            w = 1.0\n",
    "            kl_loss += w * kl\n",
    "            asm_loss += w * asm\n",
    "    return alpha * l1 + (1 - beta) * l2 + beta * kl_loss + gamma * asm_loss\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    qat=False,\n",
    "    num_epochs=50,\n",
    "    method_name=\"MTSD\",\n",
    "):\n",
    "    model.to(device)\n",
    "\n",
    "    # ---- QAT setup ----\n",
    "    if qat:\n",
    "        # Define QAT configuration\n",
    "        model.qconfig = torch.quantization.get_default_qat_qconfig(\"fbgemm\")\n",
    "        # Prepare model for QAT\n",
    "        torch.quantization.prepare_qat(model, inplace=True)\n",
    "        print(\"[QAT] Model prepared for Quantization-Aware Training\")\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    delta = torch.tensor(0.5, requires_grad=True, device=device)\n",
    "    delta_opt = optim.Adam([delta], lr=1e-3)\n",
    "\n",
    "    for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds, feats = model(x)\n",
    "            loss = compute_total_loss(preds, feats, y, delta=delta)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            delta_opt.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        val_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds, _ = model(x)\n",
    "                pred = preds[-1].argmax(1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        acc = correct / total\n",
    "        print(\n",
    "            f\"[MTSD{'-QAT' if qat else ''}] Epoch {epoch}: Loss = {val_loss:.4f}, Acc = {acc:.4f}\"\n",
    "        )\n",
    "\n",
    "    # ---- Convert to quantized model after QAT ----\n",
    "    if qat:\n",
    "        model.cpu()\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "        print(\"[QAT] Model converted to quantized version\")\n",
    "    torch.save(model.state_dict(), f\"models/mtsd_{method_name}.pth\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Losses\n",
    "# -------------------------------\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature=4.0, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, targets):\n",
    "        hard_loss = self.ce(student_logits, targets)\n",
    "        T = self.temperature\n",
    "        soft_loss = F.kl_div(\n",
    "            F.log_softmax(student_logits / T, dim=1),\n",
    "            F.softmax(teacher_logits / T, dim=1),\n",
    "            reduction=\"batchmean\",\n",
    "        ) * (T * T)\n",
    "        return self.alpha * hard_loss + (1 - self.alpha) * soft_loss\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Training helpers\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "def get_resnet_teacher(num_classes=5, pretrained=True):\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_teacher(model, train_loader, val_loader, device, epochs=10):\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = ce(model(x), y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    torch.save(model.state_dict(), \"models/teacher.pth\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate a MultiBranchNet or similar model.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        loader: DataLoader for evaluation\n",
    "        device: \"cuda\" or \"cpu\"\n",
    "\n",
    "    Returns:\n",
    "        Accuracy (float)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)          # unpack logits and features\n",
    "            preds = logits[-1].argmax(1)  # use last branch for final prediction\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# KD Methods\n",
    "# -------------------------------\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def normal_kd(student, teacher, train_loader, val_loader, device, epochs=10):\n",
    "    \"\"\"\n",
    "    Train a student model using Knowledge Distillation from a teacher.\n",
    "\n",
    "    Args:\n",
    "        student: student model (MultiBranchNet)\n",
    "        teacher: teacher model\n",
    "        train_loader: DataLoader for training\n",
    "        val_loader: DataLoader for validation\n",
    "        device: \"cuda\" or \"cpu\"\n",
    "        epochs: number of epochs\n",
    "\n",
    "    Returns:\n",
    "        Trained student model\n",
    "    \"\"\"\n",
    "\n",
    "    student.to(device)\n",
    "    teacher.to(device).eval()\n",
    "    kd_loss = DistillationLoss()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # Teacher logits\n",
    "            with torch.no_grad():\n",
    "                tlogits = teacher(x)\n",
    "\n",
    "            # Student logits (last branch only)\n",
    "            slogits, _ = student(x)\n",
    "            loss = kd_loss(slogits[-1], tlogits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        student.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits, _ = student(x)\n",
    "                preds = logits[-1].argmax(1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        acc = correct / total\n",
    "        print(f\"[Normal KD] Epoch {epoch}: Loss = {avg_loss:.4f}, Acc = {acc:.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(student.state_dict(), \"models/student.pth\")\n",
    "    return student\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5e52da-e521-476f-85bf-2a655dcbd6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Standard and augmented loaders\n",
    "# train_loader1, val_loader1, test_loader1 = prepare_dataloaders(\n",
    "#     \"data\", batch_size=32, augment=False, num_workers=4\n",
    "# )\n",
    "# train_loader_aug1, val_loader1, test_loader1 = prepare_dataloaders(\n",
    "#     \"data\", batch_size=32, augment=True, num_workers=4\n",
    "# )\n",
    "\n",
    "# NUM_CLASSES_1 = len(train_loader1.dataset.dataset.classes)\n",
    "\n",
    "train_loader2, val_loader2, test_loader2 = prepare_dataloaders(\n",
    "    \"data2/Dataset\", batch_size=32, augment=False, num_workers=4\n",
    ")\n",
    "train_loader_aug2, val_loader2, test_loader2 = prepare_dataloaders(\n",
    "    \"data2/Dataset\", batch_size=32, augment=True, num_workers=4\n",
    ")\n",
    "\n",
    "NUM_CLASSES_2 = len(train_loader2.dataset.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc291c33-0586-4950-a908-54c3fa485a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = train_loader2, val_loader2, test_loader2\n",
    "train_loader_aug, val_loader, test_loader = train_loader_aug2, val_loader2, test_loader2\n",
    "NUM_CLASSES = NUM_CLASSES_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c64740-0cd5-4db1-9d8a-d5df4a683614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/mykernel/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/workspace/mykernel/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 20/20 [00:09<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "teacher = train_teacher(\n",
    "    get_resnet_teacher(num_classes=NUM_CLASSES),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7502809-64f6-4405-9224-2c8d0ec17235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:03<00:59,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 1: Loss = 6.1379, Acc = 0.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:04<00:41,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 2: Loss = 5.0429, Acc = 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:06<00:34,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 3: Loss = 4.4378, Acc = 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:08<00:30,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 4: Loss = 3.9135, Acc = 0.4773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:10<00:28,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 5: Loss = 3.1474, Acc = 0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:11<00:25,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 6: Loss = 2.7623, Acc = 0.5682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:13<00:23,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 7: Loss = 2.1422, Acc = 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:15<00:21,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 8: Loss = 1.8753, Acc = 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:16<00:19,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 9: Loss = 1.7106, Acc = 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:18<00:17,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 10: Loss = 1.4717, Acc = 0.7045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:20<00:15,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 11: Loss = 0.9106, Acc = 0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:22<00:14,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 12: Loss = 0.8441, Acc = 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:23<00:12,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 13: Loss = 0.8146, Acc = 0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:25<00:10,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 14: Loss = 0.6426, Acc = 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:27<00:08,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 15: Loss = 0.5845, Acc = 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:29<00:06,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 16: Loss = 0.4890, Acc = 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:30<00:05,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 17: Loss = 0.4752, Acc = 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:32<00:03,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 18: Loss = 0.5519, Acc = 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:34<00:01,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 19: Loss = 0.3053, Acc = 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:36<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 20: Loss = 0.4364, Acc = 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6818181818181818 1555800\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 1: Normal KD (unchanged)\n",
    "# ----------------------------\n",
    "s1 = normal_kd(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    teacher,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=20,\n",
    ")\n",
    "\n",
    "acc1 = evaluate(s1, val_loader, device)\n",
    "size1 = sum(p.numel() for p in s1.parameters())\n",
    "results[\"Normal KD\"] = { \"acc\": acc1, \"size\":  size1}\n",
    "print(acc1, size1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b25f98-df99-4569-9257-c22e7de86b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:01<00:34,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 1: Loss = 4.2358, Acc = 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:03<00:32,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 2: Loss = 3.5375, Acc = 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:05<00:30,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 3: Loss = 2.8886, Acc = 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:07<00:28,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 4: Loss = 2.5597, Acc = 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:09<00:27,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 5: Loss = 2.6640, Acc = 0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:10<00:25,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 6: Loss = 2.5547, Acc = 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:12<00:23,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 7: Loss = 2.4740, Acc = 0.6591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:14<00:21,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 8: Loss = 2.2439, Acc = 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:16<00:19,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 9: Loss = 2.0396, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:18<00:18,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 10: Loss = 1.9670, Acc = 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:19<00:16,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 11: Loss = 1.9725, Acc = 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:21<00:14,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 12: Loss = 1.9282, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:23<00:12,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 13: Loss = 2.2216, Acc = 0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:25<00:10,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 14: Loss = 1.9884, Acc = 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:27<00:09,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 15: Loss = 2.0131, Acc = 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:28<00:07,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 16: Loss = 1.9884, Acc = 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:30<00:05,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 17: Loss = 2.0359, Acc = 0.6136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:32<00:03,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 18: Loss = 1.7617, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:34<00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 19: Loss = 1.6978, Acc = 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:36<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 20: Loss = 1.6983, Acc = 0.7045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6590909090909091 1555800\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 2: Normal KD (Augmentation)\n",
    "# ----------------------------\n",
    "s2 = normal_kd(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    teacher,\n",
    "    train_loader_aug,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=20,\n",
    ")\n",
    "acc2 = evaluate(s2, val_loader, device)\n",
    "size2 = sum(p.numel() for p in s2.parameters())\n",
    "results[\"Normal KD with AUG\"] = { \"acc\": acc2, \"size\":  size2}\n",
    "print(acc2, size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b1d952-ce84-4721-a30e-288a7385dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:02<00:40,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 1: Loss = 5.5708, Acc = 0.2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:04<00:36,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 2: Loss = 5.1060, Acc = 0.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:06<00:34,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 3: Loss = 4.7970, Acc = 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:08<00:32,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 4: Loss = 4.2679, Acc = 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:10<00:30,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 5: Loss = 4.0170, Acc = 0.4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:12<00:28,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 6: Loss = 3.4600, Acc = 0.4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:14<00:26,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 7: Loss = 3.2893, Acc = 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:16<00:24,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 8: Loss = 3.1835, Acc = 0.4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:18<00:22,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 9: Loss = 2.9799, Acc = 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:20<00:20,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 10: Loss = 3.1432, Acc = 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:22<00:18,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 11: Loss = 2.7178, Acc = 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:24<00:16,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 12: Loss = 2.7850, Acc = 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:26<00:14,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 13: Loss = 2.6327, Acc = 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:28<00:12,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 14: Loss = 2.5822, Acc = 0.6136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:30<00:10,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 15: Loss = 2.6560, Acc = 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:32<00:08,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 16: Loss = 2.5161, Acc = 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:34<00:06,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 17: Loss = 2.5350, Acc = 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:36<00:04,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 18: Loss = 2.5225, Acc = 0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:38<00:02,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 19: Loss = 2.4700, Acc = 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:40<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 20: Loss = 2.4530, Acc = 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5909090909090909 1555800\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 3: Multi-Teacher KD (MTSD)\n",
    "# ----------------------------\n",
    "s3 = train(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    qat=False,\n",
    "    num_epochs=20,\n",
    "    method_name=\"MTSD\",\n",
    ")\n",
    "\n",
    "\n",
    "acc3 = evaluate(s3, val_loader, device)\n",
    "size3 = sum(p.numel() for p in s3.parameters())\n",
    "results[\"Multi-Teacher SD\"] = { \"acc\": acc3, \"size\":  size3}\n",
    "print(acc3, size3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfee931-74ef-4109-a2f2-441e32797472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:02<00:39,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 1: Loss = 5.5652, Acc = 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:04<00:37,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 2: Loss = 5.1146, Acc = 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:06<00:35,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 3: Loss = 5.0700, Acc = 0.4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:08<00:33,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 4: Loss = 4.7051, Acc = 0.4318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:10<00:31,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 5: Loss = 4.6094, Acc = 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:12<00:29,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 6: Loss = 4.7180, Acc = 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:14<00:27,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 7: Loss = 4.0206, Acc = 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:16<00:25,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 8: Loss = 3.8613, Acc = 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:18<00:23,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 9: Loss = 3.8068, Acc = 0.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:20<00:20,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 10: Loss = 3.8987, Acc = 0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:22<00:18,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 11: Loss = 3.7167, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:25<00:16,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 12: Loss = 3.4387, Acc = 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:27<00:14,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 13: Loss = 3.3204, Acc = 0.7045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:29<00:12,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 14: Loss = 3.4684, Acc = 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:31<00:10,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 15: Loss = 3.1836, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:33<00:08,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 16: Loss = 3.3112, Acc = 0.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:35<00:06,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 17: Loss = 3.5704, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:37<00:04,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 18: Loss = 3.5036, Acc = 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:39<00:02,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 19: Loss = 3.0997, Acc = 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:41<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 20: Loss = 3.0986, Acc = 0.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8409090909090909 1555800\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 4: MTSD + Augmentation\n",
    "# ----------------------------\n",
    "s4 = train(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    train_loader_aug,\n",
    "    val_loader,\n",
    "    device,\n",
    "    qat=False,\n",
    "    num_epochs=20,\n",
    "    method_name=\"MTSD-Aug\",\n",
    ")\n",
    "acc4 = evaluate(s4, val_loader, device)\n",
    "size4 = sum(p.numel() for p in s4.parameters())\n",
    "results[\"MTSD + Aug\"] =  { \"acc\": acc4, \"size\":  size4}\n",
    "print(acc4, size4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7990664-d438-4329-8b28-e6ceef60fcf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8057/1318273963.py:233: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  torch.quantization.prepare_qat(model, inplace=True)\n",
      "/workspace/mykernel/lib/python3.12/site-packages/torch/ao/quantization/observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QAT] Model prepared for Quantization-Aware Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:02<00:44,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 1: Loss = 5.5363, Acc = 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:04<00:41,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 2: Loss = 5.2271, Acc = 0.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:06<00:38,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 3: Loss = 5.1329, Acc = 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:09<00:36,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 4: Loss = 4.9453, Acc = 0.4318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:11<00:34,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 5: Loss = 4.9779, Acc = 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:13<00:31,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 6: Loss = 4.6529, Acc = 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:15<00:29,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 7: Loss = 4.7352, Acc = 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:18<00:27,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 8: Loss = 4.4899, Acc = 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:20<00:24,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 9: Loss = 4.2765, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:22<00:22,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 10: Loss = 4.1706, Acc = 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:24<00:20,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 11: Loss = 4.0083, Acc = 0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:27<00:18,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 12: Loss = 3.9505, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:29<00:15,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 13: Loss = 3.9752, Acc = 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:31<00:13,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 14: Loss = 3.5785, Acc = 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:33<00:11,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 15: Loss = 3.7990, Acc = 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:36<00:09,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 16: Loss = 3.7063, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:38<00:06,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 17: Loss = 3.7520, Acc = 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:40<00:04,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 18: Loss = 3.5344, Acc = 0.7045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:42<00:02,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 19: Loss = 3.7096, Acc = 0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:45<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 20: Loss = 3.3943, Acc = 0.7727\n",
      "[QAT] Model converted to quantized version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_8057/1318273963.py:276: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  torch.quantization.convert(model, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 5: MTSD + Aug + QAT\n",
    "# ----------------------------\n",
    "s5 = train(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    train_loader_aug,\n",
    "    val_loader,\n",
    "    device,\n",
    "    qat=True,\n",
    "    num_epochs=20,\n",
    "    method_name=\"MTSD-Aug-QAT\",\n",
    ")\n",
    "\n",
    "# acc5 = evaluate(s5, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3552677b-d6be-414d-a496-5c9ff74b5372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n"
     ]
    }
   ],
   "source": [
    "size5 = sum(p.numel() for p in s5.parameters())\n",
    "results[\"MTSD-Aug-QAT\"] = { \"acc\": 0.7727, \"size\":  size5}\n",
    "print(size5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfe9c3d6-2564-4277-b4bd-7228045757c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal KD': {'acc': 0.6818181818181818, 'size': 1555800},\n",
       " 'Normal KD with AUG': {'acc': 0.6590909090909091, 'size': 1555800},\n",
       " 'Multi-Teacher SD': {'acc': 0.5909090909090909, 'size': 1555800},\n",
       " 'MTSD + Aug': {'acc': 0.8409090909090909, 'size': 1555800},\n",
       " 'MTSD-Aug-QAT': {'acc': 0.7727, 'size': 1920}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mykernel)",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
