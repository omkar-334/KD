{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc7db756-79c2-4dd6-af9e-41e4df1e97fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def prepare_dataloaders(\n",
    "    path, batch_size=32, num_workers=2, val_split=0.2, test_split=0.1, augment=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepares train, validation, and test dataloaders from an ImageFolder dataset.\n",
    "    Supports optional data augmentation for the training set.\n",
    "\n",
    "    Args:\n",
    "        path (str): Root directory path to the dataset.\n",
    "        batch_size (int): Number of samples per batch.\n",
    "        num_workers (int): Number of subprocesses for data loading.\n",
    "        val_split (float): Fraction of data to use for validation.\n",
    "        test_split (float): Fraction of data to use for testing.\n",
    "        augment (bool): If True, apply augmentation to training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader or None)\n",
    "    \"\"\"\n",
    "    # Base transform (resize + normalize)\n",
    "    base_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Augmented transform for training only\n",
    "    aug_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load full dataset (with base transform first)\n",
    "    full_dataset = datasets.ImageFolder(root=path, transform=base_transform)\n",
    "\n",
    "    total_size = len(full_dataset)\n",
    "    test_size = int(total_size * test_split)\n",
    "    val_size = int(total_size * val_split)\n",
    "    train_size = total_size - val_size - test_size\n",
    "\n",
    "    if test_split > 0:\n",
    "        train_set, val_set, test_set = random_split(\n",
    "            full_dataset,\n",
    "            [train_size, val_size, test_size],\n",
    "            generator=torch.Generator().manual_seed(42),\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=False,\n",
    "        )\n",
    "    else:\n",
    "        train_set, val_set = random_split(\n",
    "            full_dataset,\n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(42),\n",
    "        )\n",
    "        test_loader = None\n",
    "\n",
    "    # Apply augmentation only to training subset if requested\n",
    "    if augment:\n",
    "        train_set.dataset.transform = aug_transform\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Simple MTSD model\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "# ========== ECA and Backbone ==========\n",
    "class ECALayer(nn.Module):\n",
    "    def __init__(self, channels, k_size=3):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(\n",
    "            1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x).squeeze(-1).transpose(1, 2)\n",
    "        y = self.conv(y).transpose(1, 2).unsqueeze(-1)\n",
    "        y = self.sigmoid(y)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class Branch(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class MultiBranchNet(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            BottleneckBlock(input_channels, 64),\n",
    "            BottleneckBlock(64, 128),\n",
    "            BottleneckBlock(128, 256),\n",
    "            BottleneckBlock(256, 512),\n",
    "        ])\n",
    "        self.att = nn.ModuleList([\n",
    "            ECALayer(64),\n",
    "            ECALayer(128),\n",
    "            ECALayer(256),\n",
    "            ECALayer(512),\n",
    "        ])\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            Branch(64, num_classes),\n",
    "            Branch(128, num_classes),\n",
    "            Branch(256, num_classes),\n",
    "            Branch(512, num_classes),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features, logits = [], []\n",
    "        for i in range(4):\n",
    "            x = self.blocks[i](x)\n",
    "            x = self.att[i](x)\n",
    "            features.append(x)\n",
    "            logits.append(self.classifiers[i](x))\n",
    "        return logits, features\n",
    "\n",
    "\n",
    "def compute_asm(feature_map, target_size=None, max_hw=400):\n",
    "    if target_size is not None:\n",
    "        feature_map = F.interpolate(\n",
    "            feature_map, size=target_size, mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "    B, C, H, W = feature_map.size()\n",
    "    if max_hw < H * W:\n",
    "        feature_map = F.adaptive_avg_pool2d(\n",
    "            feature_map, (int(max_hw**0.5), int(max_hw**0.5))\n",
    "        )\n",
    "    F_T = feature_map.view(B, C, -1)\n",
    "    sim = torch.bmm(F_T.transpose(1, 2), F_T)\n",
    "    norm = torch.norm(sim, dim=(1, 2), keepdim=True) + 1e-6\n",
    "    return sim / norm\n",
    "\n",
    "\n",
    "def compute_total_loss(preds, feats, labels, alpha=3, beta=0.3, gamma=3000, delta=None):\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    l1 = ce(preds[3], labels)\n",
    "    l2 = sum(ce(preds[i], labels) for i in range(3))\n",
    "    kl_loss, asm_loss = 0, 0\n",
    "    target_size = feats[3].shape[2:]\n",
    "    for i in range(3):\n",
    "        pi = F.log_softmax(preds[i], dim=1)\n",
    "        for j in range(i + 1, 4):\n",
    "            pj = F.softmax(preds[j].detach(), dim=1)\n",
    "            kl = F.kl_div(pi, pj, reduction=\"batchmean\")\n",
    "            asm_s = compute_asm(feats[i], target_size)\n",
    "            asm_t = compute_asm(feats[j].detach(), target_size)\n",
    "            if asm_s.shape != asm_t.shape:\n",
    "                min_shape = list(map(min, asm_s.shape, asm_t.shape))\n",
    "                asm_s = asm_s[:, : min_shape[1], : min_shape[2]]\n",
    "                asm_t = asm_t[:, : min_shape[1], : min_shape[2]]\n",
    "            asm = F.mse_loss(asm_s, asm_t)\n",
    "            w = 1.0\n",
    "            kl_loss += w * kl\n",
    "            asm_loss += w * asm\n",
    "    return alpha * l1 + (1 - beta) * l2 + beta * kl_loss + gamma * asm_loss\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    qat=False,\n",
    "    num_epochs=50,\n",
    "    method_name=\"MTSD\",\n",
    "):\n",
    "    model.to(device)\n",
    "\n",
    "    # ---- QAT setup ----\n",
    "    if qat:\n",
    "        # Define QAT configuration\n",
    "        model.qconfig = torch.quantization.get_default_qat_qconfig(\"fbgemm\")\n",
    "        # Prepare model for QAT\n",
    "        torch.quantization.prepare_qat(model, inplace=True)\n",
    "        print(\"[QAT] Model prepared for Quantization-Aware Training\")\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    delta = torch.tensor(0.5, requires_grad=True, device=device)\n",
    "    delta_opt = optim.Adam([delta], lr=1e-3)\n",
    "\n",
    "    for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds, feats = model(x)\n",
    "            loss = compute_total_loss(preds, feats, y, delta=delta)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            delta_opt.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        val_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds, _ = model(x)\n",
    "                pred = preds[-1].argmax(1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        acc = correct / total\n",
    "        print(\n",
    "            f\"[MTSD{'-QAT' if qat else ''}] Epoch {epoch}: Loss = {val_loss:.4f}, Acc = {acc:.4f}\"\n",
    "        )\n",
    "\n",
    "    # ---- Convert to quantized model after QAT ----\n",
    "    if qat:\n",
    "        model.cpu()\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "        print(\"[QAT] Model converted to quantized version\")\n",
    "    torch.save(model.state_dict(), f\"models/mtsd_{method_name}.pth\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Losses\n",
    "# -------------------------------\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature=4.0, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, targets):\n",
    "        hard_loss = self.ce(student_logits, targets)\n",
    "        T = self.temperature\n",
    "        soft_loss = F.kl_div(\n",
    "            F.log_softmax(student_logits / T, dim=1),\n",
    "            F.softmax(teacher_logits / T, dim=1),\n",
    "            reduction=\"batchmean\",\n",
    "        ) * (T * T)\n",
    "        return self.alpha * hard_loss + (1 - self.alpha) * soft_loss\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Training helpers\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "def get_resnet_teacher(num_classes=5, pretrained=True):\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_teacher(model, train_loader, val_loader, device, epochs=10):\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = ce(model(x), y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    torch.save(model.state_dict(), \"models/teacher.pth\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate a MultiBranchNet or similar model.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        loader: DataLoader for evaluation\n",
    "        device: \"cuda\" or \"cpu\"\n",
    "\n",
    "    Returns:\n",
    "        Accuracy (float)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)          # unpack logits and features\n",
    "            preds = logits[-1].argmax(1)  # use last branch for final prediction\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# KD Methods\n",
    "# -------------------------------\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def normal_kd(student, teacher, train_loader, val_loader, device, epochs=10):\n",
    "    \"\"\"\n",
    "    Train a student model using Knowledge Distillation from a teacher.\n",
    "\n",
    "    Args:\n",
    "        student: student model (MultiBranchNet)\n",
    "        teacher: teacher model\n",
    "        train_loader: DataLoader for training\n",
    "        val_loader: DataLoader for validation\n",
    "        device: \"cuda\" or \"cpu\"\n",
    "        epochs: number of epochs\n",
    "\n",
    "    Returns:\n",
    "        Trained student model\n",
    "    \"\"\"\n",
    "\n",
    "    student.to(device)\n",
    "    teacher.to(device).eval()\n",
    "    kd_loss = DistillationLoss()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # Teacher logits\n",
    "            with torch.no_grad():\n",
    "                tlogits = teacher(x)\n",
    "\n",
    "            # Student logits (last branch only)\n",
    "            slogits, _ = student(x)\n",
    "            loss = kd_loss(slogits[-1], tlogits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        student.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits, _ = student(x)\n",
    "                preds = logits[-1].argmax(1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        acc = correct / total\n",
    "        print(f\"[Normal KD] Epoch {epoch}: Loss = {avg_loss:.4f}, Acc = {acc:.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(student.state_dict(), \"models/student.pth\")\n",
    "    return student\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5e52da-e521-476f-85bf-2a655dcbd6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Standard and augmented loaders\n",
    "# train_loader1, val_loader1, test_loader1 = prepare_dataloaders(\n",
    "#     \"data\", batch_size=32, augment=False, num_workers=4\n",
    "# )\n",
    "# train_loader_aug1, val_loader1, test_loader1 = prepare_dataloaders(\n",
    "#     \"data\", batch_size=32, augment=True, num_workers=4\n",
    "# )\n",
    "\n",
    "# NUM_CLASSES_1 = len(train_loader1.dataset.dataset.classes)\n",
    "\n",
    "\n",
    "path = 'data3/mendeley'\n",
    "train_loader3, _, _ = prepare_dataloaders(\n",
    "    path, batch_size=32, augment=False, num_workers=4\n",
    ")\n",
    "train_loader_aug3, val_loader3, test_loader3 = prepare_dataloaders(\n",
    "    path, batch_size=32, augment=True, num_workers=4\n",
    ")\n",
    "\n",
    "NUM_CLASSES_3 = len(train_loader3.dataset.dataset.classes)\n",
    "NUM_CLASSES_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc291c33-0586-4950-a908-54c3fa485a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_loader3\n",
    "train_loader_aug, val_loader, test_loader = train_loader_aug3, val_loader3, test_loader3\n",
    "NUM_CLASSES = NUM_CLASSES_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c64740-0cd5-4db1-9d8a-d5df4a683614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/mykernel/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/workspace/mykernel/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 20/20 [02:45<00:00,  8.28s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "teacher = train_teacher(\n",
    "    get_resnet_teacher(num_classes=NUM_CLASSES),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7502809-64f6-4405-9224-2c8d0ec17235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:38<12:02, 38.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 1: Loss = 7.6782, Acc = 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:14<11:10, 37.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 2: Loss = 5.6542, Acc = 0.4885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:51<10:30, 37.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 3: Loss = 4.6273, Acc = 0.4937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:28<09:52, 37.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 4: Loss = 3.9774, Acc = 0.4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [03:05<09:14, 36.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 5: Loss = 3.4172, Acc = 0.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [03:42<08:37, 36.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 6: Loss = 2.9021, Acc = 0.5367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [04:19<07:59, 36.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 7: Loss = 2.5429, Acc = 0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [04:55<07:21, 36.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 8: Loss = 2.2243, Acc = 0.5211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [05:32<06:44, 36.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 9: Loss = 1.9098, Acc = 0.5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [06:09<06:08, 36.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 10: Loss = 1.6661, Acc = 0.5196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [06:46<05:31, 36.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 11: Loss = 1.4574, Acc = 0.5715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [07:23<04:54, 36.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 12: Loss = 1.4038, Acc = 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [07:59<04:17, 36.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 13: Loss = 1.3217, Acc = 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [08:36<03:40, 36.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 14: Loss = 1.2617, Acc = 0.5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [09:13<03:04, 36.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 15: Loss = 1.0698, Acc = 0.6012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [09:50<02:27, 36.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 16: Loss = 1.0619, Acc = 0.5360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [10:27<01:50, 36.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 17: Loss = 0.9692, Acc = 0.5537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [11:04<01:13, 36.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 18: Loss = 0.9626, Acc = 0.5893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [11:40<00:36, 36.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 19: Loss = 0.8165, Acc = 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [12:17<00:00, 36.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 20: Loss = 0.8015, Acc = 0.5597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5841363973313566 1563512\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 1: Normal KD (unchanged)\n",
    "# ----------------------------\n",
    "s1 = normal_kd(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    teacher,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=20,\n",
    ")\n",
    "\n",
    "acc1 = evaluate(s1, val_loader, device)\n",
    "size1 = sum(p.numel() for p in s1.parameters())\n",
    "results[\"Normal KD\"] = { \"acc\": acc1, \"size\":  size1}\n",
    "print(acc1, size1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b25f98-df99-4569-9257-c22e7de86b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:36<11:35, 36.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 1: Loss = 3.7589, Acc = 0.4388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:13<10:59, 36.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 2: Loss = 3.1101, Acc = 0.5159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:50<10:25, 36.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 3: Loss = 2.9139, Acc = 0.5204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:27<09:49, 36.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 4: Loss = 2.6710, Acc = 0.5508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [03:04<09:13, 36.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 5: Loss = 2.5007, Acc = 0.5693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [03:41<08:36, 36.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 6: Loss = 2.4146, Acc = 0.6123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [04:17<07:59, 36.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 7: Loss = 2.3253, Acc = 0.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [04:54<07:23, 36.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 8: Loss = 2.2271, Acc = 0.6494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [05:31<06:46, 36.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 9: Loss = 2.1623, Acc = 0.6494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [06:08<06:09, 36.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 10: Loss = 2.0475, Acc = 0.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [06:45<05:32, 36.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 11: Loss = 1.9812, Acc = 0.5997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [07:22<04:55, 36.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 12: Loss = 1.9718, Acc = 0.6590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [07:59<04:18, 36.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 13: Loss = 1.9182, Acc = 0.6331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [08:36<03:41, 36.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 14: Loss = 1.8454, Acc = 0.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [09:13<03:04, 36.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 15: Loss = 1.7744, Acc = 0.6990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [09:50<02:27, 36.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 16: Loss = 1.7575, Acc = 0.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [10:27<01:50, 36.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 17: Loss = 1.7121, Acc = 0.6783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [11:03<01:13, 36.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 18: Loss = 1.7276, Acc = 0.7405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [11:40<00:36, 36.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 19: Loss = 1.6571, Acc = 0.6909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [12:17<00:00, 36.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normal KD] Epoch 20: Loss = 1.6326, Acc = 0.7035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6997776130467013 1563512\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 2: Normal KD (Augmentation)\n",
    "# ----------------------------\n",
    "s2 = normal_kd(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    teacher,\n",
    "    train_loader_aug,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=20,\n",
    ")\n",
    "acc2 = evaluate(s2, val_loader, device)\n",
    "size2 = sum(p.numel() for p in s2.parameters())\n",
    "results[\"Normal KD with AUG\"] = { \"acc\": acc2, \"size\":  size2}\n",
    "print(acc2, size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b1d952-ce84-4721-a30e-288a7385dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:45<14:17, 45.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 1: Loss = 8.7630, Acc = 0.4077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:30<13:30, 45.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 2: Loss = 7.2048, Acc = 0.4329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:15<12:46, 45.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 3: Loss = 6.4222, Acc = 0.4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [03:00<12:01, 45.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 4: Loss = 5.9646, Acc = 0.3647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [03:45<11:16, 45.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 5: Loss = 5.6228, Acc = 0.4589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [04:30<10:31, 45.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 6: Loss = 5.2439, Acc = 0.4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [05:15<09:46, 45.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 7: Loss = 4.9864, Acc = 0.4181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [06:00<09:01, 45.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 8: Loss = 4.6881, Acc = 0.4855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [06:45<08:15, 45.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 9: Loss = 4.4641, Acc = 0.4485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [07:30<07:31, 45.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 10: Loss = 4.1600, Acc = 0.4255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [08:16<06:46, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 11: Loss = 3.6033, Acc = 0.4811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [09:01<06:01, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 12: Loss = 3.4813, Acc = 0.4692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [09:46<05:16, 45.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 13: Loss = 3.4431, Acc = 0.4796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [10:31<04:30, 45.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 14: Loss = 3.3914, Acc = 0.5033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [11:16<03:45, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 15: Loss = 3.3763, Acc = 0.4893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [12:01<03:00, 45.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 16: Loss = 3.3443, Acc = 0.4944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [12:46<02:15, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 17: Loss = 3.2809, Acc = 0.4944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [13:32<01:30, 45.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 18: Loss = 3.2785, Acc = 0.4752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [14:17<00:45, 45.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 19: Loss = 3.2328, Acc = 0.4766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [15:02<00:00, 45.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 20: Loss = 3.2539, Acc = 0.5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5040770941438102 1563512\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 3: Multi-Teacher KD (MTSD)\n",
    "# ----------------------------\n",
    "s3 = train(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    qat=False,\n",
    "    num_epochs=20,\n",
    "    method_name=\"MTSD\",\n",
    ")\n",
    "\n",
    "\n",
    "acc3 = evaluate(s3, val_loader, device)\n",
    "size3 = sum(p.numel() for p in s3.parameters())\n",
    "results[\"Multi-Teacher SD\"] = { \"acc\": acc3, \"size\":  size3}\n",
    "print(acc3, size3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfee931-74ef-4109-a2f2-441e32797472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:45<14:19, 45.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 1: Loss = 9.5831, Acc = 0.4285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:30<13:32, 45.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 2: Loss = 8.3997, Acc = 0.5293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:15<12:46, 45.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 3: Loss = 7.7424, Acc = 0.5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [03:00<12:02, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 4: Loss = 7.2866, Acc = 0.5686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [03:45<11:17, 45.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 5: Loss = 6.8582, Acc = 0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [04:30<10:31, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 6: Loss = 6.6933, Acc = 0.6019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [05:16<09:47, 45.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 7: Loss = 6.3243, Acc = 0.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [06:01<09:02, 45.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 8: Loss = 6.0629, Acc = 0.6635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [06:46<08:17, 45.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 9: Loss = 5.8250, Acc = 0.6442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [07:31<07:31, 45.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 10: Loss = 5.7909, Acc = 0.6657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [08:16<06:45, 45.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 11: Loss = 5.1479, Acc = 0.7591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [09:01<06:01, 45.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 12: Loss = 5.0687, Acc = 0.7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [09:46<05:15, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 13: Loss = 4.9428, Acc = 0.7776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [10:31<04:30, 45.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 14: Loss = 4.9422, Acc = 0.7761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [11:16<03:45, 45.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 15: Loss = 4.8551, Acc = 0.7917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [12:02<03:00, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 16: Loss = 4.8277, Acc = 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [12:47<02:15, 45.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 17: Loss = 4.8373, Acc = 0.8058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [13:32<01:30, 45.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 18: Loss = 4.7038, Acc = 0.8095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [14:17<00:45, 45.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 19: Loss = 4.6614, Acc = 0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [15:02<00:00, 45.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD] Epoch 20: Loss = 4.6564, Acc = 0.7939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7976278724981468 1563512\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 4: MTSD + Augmentation\n",
    "# ----------------------------\n",
    "s4 = train(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    train_loader_aug,\n",
    "    val_loader,\n",
    "    device,\n",
    "    qat=False,\n",
    "    num_epochs=20,\n",
    "    method_name=\"MTSD-Aug\",\n",
    ")\n",
    "acc4 = evaluate(s4, val_loader, device)\n",
    "size4 = sum(p.numel() for p in s4.parameters())\n",
    "results[\"MTSD + Aug\"] =  { \"acc\": acc4, \"size\":  size4}\n",
    "print(acc4, size4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7990664-d438-4329-8b28-e6ceef60fcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11389/1318273963.py:233: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  torch.quantization.prepare_qat(model, inplace=True)\n",
      "/workspace/mykernel/lib/python3.12/site-packages/torch/ao/quantization/observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QAT] Model prepared for Quantization-Aware Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:50<16:01, 50.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 1: Loss = 10.0534, Acc = 0.3781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:41<15:10, 50.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 2: Loss = 8.6400, Acc = 0.4611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:31<14:18, 50.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 3: Loss = 7.8725, Acc = 0.5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [03:21<13:27, 50.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 4: Loss = 7.4888, Acc = 0.5738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [04:12<12:35, 50.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 5: Loss = 7.1770, Acc = 0.5271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [05:02<11:45, 50.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 6: Loss = 6.8508, Acc = 0.5463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [05:53<10:55, 50.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 7: Loss = 6.5743, Acc = 0.6227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [06:43<10:05, 50.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 8: Loss = 6.4162, Acc = 0.6130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [07:34<09:15, 50.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 9: Loss = 6.2423, Acc = 0.6360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [08:24<08:24, 50.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 10: Loss = 6.0232, Acc = 0.6442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [09:15<07:34, 50.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 11: Loss = 5.5077, Acc = 0.6976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [10:05<06:43, 50.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 12: Loss = 5.3178, Acc = 0.7213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [10:56<05:53, 50.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 13: Loss = 5.3194, Acc = 0.7265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [11:46<05:02, 50.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 14: Loss = 5.2497, Acc = 0.7331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [12:37<04:12, 50.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 15: Loss = 5.2552, Acc = 0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [13:27<03:21, 50.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 16: Loss = 5.2186, Acc = 0.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [14:17<02:31, 50.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 17: Loss = 5.1382, Acc = 0.7368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [15:08<01:40, 50.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 18: Loss = 5.0948, Acc = 0.7391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [15:58<00:50, 50.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 19: Loss = 5.1151, Acc = 0.7554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [16:49<00:00, 50.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTSD-QAT] Epoch 20: Loss = 5.0721, Acc = 0.7554\n",
      "[QAT] Model converted to quantized version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_11389/1318273963.py:276: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  torch.quantization.convert(model, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Method 5: MTSD + Aug + QAT\n",
    "# ----------------------------\n",
    "s5 = train(\n",
    "    MultiBranchNet(num_classes=NUM_CLASSES),\n",
    "    train_loader_aug,\n",
    "    val_loader,\n",
    "    device,\n",
    "    qat=True,\n",
    "    num_epochs=20,\n",
    "    method_name=\"MTSD-Aug-QAT\",\n",
    ")\n",
    "\n",
    "# acc5 = evaluate(s5, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3552677b-d6be-414d-a496-5c9ff74b5372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n"
     ]
    }
   ],
   "source": [
    "size5 = sum(p.numel() for p in s5.parameters())\n",
    "results[\"MTSD-Aug-QAT\"] = { \"acc\": 0.7727, \"size\":  size5}\n",
    "print(size5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe9c3d6-2564-4277-b4bd-7228045757c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal KD': {'acc': 0.5841363973313566, 'size': 1563512},\n",
       " 'Normal KD with AUG': {'acc': 0.6997776130467013, 'size': 1563512},\n",
       " 'Multi-Teacher SD': {'acc': 0.5040770941438102, 'size': 1563512},\n",
       " 'MTSD + Aug': {'acc': 0.7976278724981468, 'size': 1563512},\n",
       " 'MTSD-Aug-QAT': {'acc': 0.7727, 'size': 1920}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mykernel)",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
